---
title: "Random Forest Model"
author: "Varun Vipul Chodanker"
format: html
editor: visual
---

## Random Forest Model

This document includes a random forest implementation on the re-balanced training data. Then, it tests its performance on the original test data.

## Setup

First, clear the environment, set configuration parameters and load the required libraries.

```{r}

# Reset environment
rm(list=ls())

library(caret)
library(readxl)
library(ranger)
library(dplyr)
library(mlr3)
library(pROC)
library(doMC)

# Configure the parallel backend to: #cores - 1
registerDoMC(7)
```

## Data Loading and Preparation

Load the re-balanced training and original test datasets. Then, prepare them accordingly.

First define utility functions for data description, column name standardisation and target type preparation.

```{r}

# Utility functions

desc_bkrpt_data = function(data, name) {
  print("--- Bankruptcy Dataset")
  print(sprintf("Name: %s", name))
  print("Dimensions: ")
  dim(data)
  print(paste0(
    "Proportion that is bankrupt: ", 
    sum(data$Bankrupt == "is_bankrupt")/dim(data)[1]
  ))
  print("Outline: ")
  str(data)
  print("---")
}

# Standardises column names assuming the target is first, then the features
standardise_column_names = function(data) {
  # Target
  names(data)[1] = "y"
  # Features
  names(data)[-1] = paste0('x', 1:(ncol(data)-1))
  
  return(data)
}

# Converts Bankrupt target to categorical for the training of a classification model
prep_class_targ = function(data) {
  data$Bankrupt = as.factor(data$Bankrupt)
  levels(data$Bankrupt) <- c("not_bankrupt", "is_bankrupt")
  return(data)
}

# Filter to passed in column names...
filter_features = function(data, colnames) {
  return(
    data %>%
      select(all_of(colnames))
  )
}
```

Read wrapper for a dataframe

```{r}

read_xlsx_to_df = function(fp) {
  return(
    data.frame(read_excel(fp))
  )
}
```

Load all the variants of the training data and the test data in.

```{r}

# Load the training data in
train.data = read_xlsx_to_df("./Datasets/train.xlsx")
# Load the balanced training data in
train_bal.data = read_xlsx_to_df("./Datasets/train_bal.xlsx")
# Load the feature selected training data in
train.feat_sel.data = read_xlsx_to_df("./Datasets/train_feat_sel.xlsx")
# Load the feature selected balanced training data in
train_bal.feat_sel.data = read_xlsx_to_df("./Datasets/train_bal_feat_sel.xlsx")

# Load the test data in
test.data = read_xlsx_to_df("./Datasets/test.xlsx")
# Feature selected version of the test data
test.feat_sel.data = filter_features(test.data, names(train.feat_sel.data))
```

Inspect the loaded data sets here.

```{r}

str(train.data)
```

Convert the target of the data sets to ensure use for classification.

```{r}

# Target conversion for classification
train.data = prep_class_targ(train.data)
train_bal.data = prep_class_targ(train_bal.data)
train.feat_sel.data = prep_class_targ(train.feat_sel.data)
train_bal.feat_sel.data = prep_class_targ(train_bal.feat_sel.data)

test.data = prep_class_targ(test.data)
test.feat_sel.data = prep_class_targ(test.feat_sel.data)
```

Confirm the data sets are ready here.

```{r}

desc_bkrpt_data(train.data, "Train")
```

## Model Training and Evaluation

Create utility function related to the weight/weights of the minority bankrupt class.

```{r}

# compared to a weight of 1 for the other non-bankrupt class
get_bankrupt_weight = function (data) {
  return (
    sum(data$Bankrupt == "not_bankrupt") / sum(data$Bankrupt == "is_bankrupt")
  )
}

get_sample_bankrupt_weights = function (data) {
  ws = rep(0, nrow(data))
  not_bankrupt_weight = 1
  is_bankrupt_weight = get_bankrupt_weight(data)
  
  ws[data$Bankrupt == "not_bankrupt"] = not_bankrupt_weight
  ws[data$Bankrupt == "is_bankrupt"] = is_bankrupt_weight
  
  return(ws)
}

get_bankrupt_class_weights = function (data) {
  return (
    c(1, get_bankrupt_weight(data))
  )
}

# Create 5 fold cv, sensitivity, specificity, ROC control
cv5foldCtrl <- trainControl(method="cv", number=5, classProbs = TRUE, summaryFunction = twoClassSummary, allowParallel = TRUE) 
```

Train a random forest model on caret. Employ 5 fold cross validation that optimises sensitivity.

```{r}

# num.trees = c(10, 30, 50), 
# max.depth = c(5, 10, 15)

get_ranger_grid = function(feat_sel) {
  if (feat_sel) {
    return (
      expand.grid(mtry = c(3, 12, 29, 51),
           min.node.size=c(1, 3, 5, 7, 9),
           splitrule=c("gini", "extratrees", "hellinger")
      )
    )
  }
  else {
    return (
      expand.grid(mtry = c(3, 12, 29, 47, 73, 91),
           min.node.size=c(1, 3, 5, 7, 9),
           splitrule=c("gini", "extratrees", "hellinger")
      )
    )
  }
}

fit_ranger = function(data, feat_sel=FALSE) {
  rangerGrid = get_ranger_grid(feat_sel)
  
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], method="ranger", 
      metric="ROC", trControl=cv5foldCtrl, tuneGrid=rangerGrid, 
      num.trees=50, max.depth=3, regularization.usedepth = TRUE, 
      weights=get_sample_bankrupt_weights(data), class.weights=get_bankrupt_class_weights(data)
    )
  )
}

# assumes balanced data input
fit_ranger_on_balanced = function(data, feat_sel=FALSE) {
  rangerGrid = get_ranger_grid(feat_sel)
  
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], method="ranger", 
      metric="ROC", trControl=cv5foldCtrl, tuneGrid=rangerGrid, 
      num.trees=50, max.depth=3, regularization.usedepth = TRUE
    )
  )
}
```

Now evaluate the model on the test data with its confusion matrix

```{r}
# Performance on reserved test data

# Expects standardised column names.
evaluate_model = function(model, eval_data) {
  # Make predictons
  eval_pred = NULL
  
  # Ensure just the raw predictions are extracted for further processing
  if (inherits(model, "ranger")) {
    eval_pred = predict(model, data=eval_data)
    eval_pred = eval_pred$predictions
  }
  else {
    eval_pred = predict(model, newdata=eval_data)  
  }
  # write.csv(eval_pred, "predictionsModel.csv")
  
  # Report performance with metrics and the confusion matrix
  print(postResample(pred=eval_pred, obs=eval_data$Bankrupt))
  print(confusionMatrix(eval_pred, eval_data$Bankrupt))
}
```

Also evaluate it based on its ROC and AUC.

```{r}

evaluate_roc = function(model, eval_data, model_name="Unknown") {
  eval_pred = predict(model, eval_data, type="prob")[,2]
  roc_obj = roc(response = eval_data$Bankrupt, levels=c("not_bankrupt", "is_bankrupt"), predictor=eval_pred)
  print(
    ggroc(roc_obj, legacy.axes = TRUE) + labs(x = 'Specificity', y = 'Sensitivity', title = paste0(model_name, ' Model ROC curve'))
  )
 print(paste0("AUC is ", auc(roc_obj)))
}
```

Now train the same model on the balanced training set.

```{r}

# Train the random forest model on the training data
train.fit.rf <- fit_ranger(train.data)
# Train the random forest model on the balanced training data
train_bal.fit.rf <- fit_ranger_on_balanced(train_bal.data)
# Feature selected versions
train.feat_sel.fit.rf <- fit_ranger(train.feat_sel.data, feat_sel = TRUE)
train_bal.feat_sel.fit.rf <- fit_ranger_on_balanced(train_bal.feat_sel.data, feat_sel = TRUE)
```

```{r}

get_test_set = function(feat_sel) {
  if (feat_sel) {
    return (test.feat_sel.data)
  }
  else {
    return (test.data)
  }
}

apply_eval_pipeline = function(model, feat_sel=FALSE, model_name="Unknown") {
  eval_data= get_test_set(feat_sel)
  print(paste0("-- ", model_name))
  # evaluate_model(model, eval_data)
  evaluate_roc(model, eval_data, model_name)
}
```

```{r}

apply_eval_pipeline(train.fit.rf, model_name = "T RF")
apply_eval_pipeline(train_bal.fit.rf, model_name = "TB RF")
apply_eval_pipeline(train.feat_sel.fit.rf, feat_sel = TRUE, model_name = "TF RF")
apply_eval_pipeline(train_bal.feat_sel.fit.rf, feat_sel = TRUE, model_name = "TBF RF")
```

Don't run the below cell

```{r}

# Define task and learner
task <- makeClassifTask(id = "bankruptcy",
                        data = adasyn.train.data,
                        target = "y")

learner <- makeLearner("classif.ranger", num.threads = 7)

# Choose resampling strategy and define grid
rdesc <- makeResampleDesc("CV", iters = 5)

ps <- makeParamSet(makeDiscreteParam("mtry", c(3, 12, 29, 47, 73, 94)), 
                   makeDiscreteParam("min.node.size", c(1, 3, 5)), 
                   makeDiscreteParam("splitrule", c("gini", "extratrees", "hellinger")), 
                   makeDiscreteParam("num.trees", c(30, 40, 50, 60, 70)), 
                   makeDiscreteParam("max.depth", c(1, 3, 5, 7, 11))
)

# Tune
res = tuneParams(learner, task, rdesc, par.set = ps,
           control = makeTuneControlGrid())

# Train on entire dataset (using best hyperparameters)
lrn = setHyperPars(makeLearner("classif.ranger"), par.vals = res$x)
m = train(lrn, task)

```

```{r}

xgbmGrid <-  expand.grid(max_depth = c(3, 6, 9), 
                        # default values below
                        nrounds = 100,    # number of trees
                        eta = 0.3,
                        gamma = c(5, 15),
                        subsample = 0.65, 
                        colsample_bytree = 0.7, 
                        min_child_weight = c(1, 3)
                        )

# training a XGboost Regression tree model while tuning parameters
fit_xgbm = function(data) {
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], 
      method = "xgbTree", metric="ROC", 
      trControl = cv5foldCtrl, tuneGrid = xgbmGrid, 
      scale_pos_weight=get_bankrupt_weight(data)
    )
  )
}

fit_xgbm_on_balanced = function(data) {
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], 
      method = "xgbTree", metric="ROC", 
      trControl = cv5foldCtrl, tuneGrid = xgbmGrid
    )
  )
}
```

```{r}
train.fit.xgbm = fit_xgbm(train.data)
train_bal.fit.xgbm = fit_xgbm_on_balanced(train_bal.data)
train.feat_sel.fit.xgbm = fit_xgbm(train.feat_sel.data)
train_bal.feat_sel.fit.xgbm = fit_xgbm_on_balanced(train_bal.feat_sel.data)
```

```{r}

apply_eval_pipeline(train.fit.xgbm, model_name = "T XGBM")
apply_eval_pipeline(train_bal.fit.xgbm, model_name = "TB XGBM")
apply_eval_pipeline(train.feat_sel.fit.xgbm, feat_sel = TRUE, model_name = "TF XGBM")
apply_eval_pipeline(train_bal.feat_sel.fit.xgbm, feat_sel = TRUE, model_name = "TBF XGBM")
```

```{r}

adbGrid <-  expand.grid(
                        mfinal= c(50, 100), 
                        maxdepth= c(20, 30)
                        )

# training a XGboost Regression tree model while tuning parameters
fit_adb = function(data) {
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], 
      method = "AdaBag", metric="ROC", 
      trControl = cv5foldCtrl, tuneGrid = adbGrid, 
      weights=get_sample_bankrupt_weights(data)
    )
  )  
}

fit_adb_on_balanced = function(data) {
  return (
    train(
      x=data[, names(data) != 'Bankrupt'], 
      y=data[["Bankrupt"]], 
      method = "AdaBag", metric="ROC", 
      trControl = cv5foldCtrl, tuneGrid = adbGrid
    )
  )  
}
```

```{r}

train.fit.adb = fit_adb(train.data)
train_bal.fit.adb = fit_adb_on_balanced(train_bal.data)
train.feat_sel.fit.adb = fit_adb(train.feat_sel.data)
train_bal.feat_sel.fit.adb = fit_adb_on_balanced(train_bal.feat_sel.data)
```

```{r}

apply_eval_pipeline(train.fit.adb, model_name = "T ADB")
apply_eval_pipeline(train_bal.fit.adb, model_name = "TB ADB")
apply_eval_pipeline(train.feat_sel.fit.adb, feat_sel = TRUE, model_name = "TF ADB")
apply_eval_pipeline(train_bal.feat_sel.fit.adb, feat_sel = TRUE, model_name = "TBF ADB")
```

```{r}

baseCtrl <- trainControl(method="none", classProbs = TRUE, summaryFunction = twoClassSummary, allowParallel = TRUE)

gamModel = train(
  x=train_bal.data[, names(train_bal.data) != 'Bankrupt'], 
  y=train_bal.data[["Bankrupt"]], 
  method = "rotationForest", 
  trControl = baseCtrl, metric="ROC"
)

# summarising the results
```

```{r}

apply_eval_pipeline(gamModel, model_name = "GAM")
```

Report training performance of the two random forest models above.

Report the test performance of the two random forest models above.

Train and evaluate a ranger model as the alternative

```{r}

#Compute weights to balance the RF

#Fit the RF
# train.df <- data.frame(train.data$Bankrupt., train.data[,2:ncol(train.data)])
# case.weights=weights
rebalanced.fit.rrf <- ranger(y~., rebalanced.train.data)
print(rebalanced.fit.rrf)
evaluate_model(rebalanced.fit.rrf, test.data)
# test.pred = predict(rebalanced.fit.rrf, data=test.data)
# postResample(pred=test.pred$predictions, obs=test.data$y)
# confusionMatrix(test.pred$predictions, test.data$y)
```

```{r}

adasyn.fit.rrf <- ranger(y~., adasyn.train.data)
print(adasyn.fit.rrf)
evaluate_model(adasyn.fit.rrf, test.data)
# test.pred = predict(adasyn.fit.rrf, data=test.data)
# postResample(pred=test.pred$predictions, obs=test.data$y)
# confusionMatrix(test.pred$predictions, test.data$y)
```

Attempt to increase weighting towards the +1 cases in training, on top of the balancing.

```{r}

dr.adasyn.train.data <- filter_features(adasyn.train.data)

str(dr.adasyn.train.data)
```

```{r}

get_case_weights = function(data) {
  weights <- rep(0, nrow(data))
  weights[data$y == 0] = 0.03
  weights[data$y == 1] = 0.97
  print("Weight Assignment:")
  table(weights, data$y)
  
  return(
    weights
  )
}

get_class_weights = function() {
  return(c(0, 5000000))
}
```

```{r}

adasyn.fit.wrrf <- ranger(
  y~., adasyn.train.data, 
  case.weights=get_case_weights(adasyn.train.data), class.weights = get_class_weights()
)
print(adasyn.fit.wrrf)
evaluate_model(adasyn.fit.wrrf, test.data)
```

```{r}

adasyn.fit.csrf = csrf(y~., adasyn.train.data, test.data)
print(adasyn.fit.csrf)
```

```{r}

# worse performance (case-weighted random forests)
confusionMatrix(adasyn.fit.csrf, test.data$y)
```
