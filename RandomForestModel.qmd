---
title: "Random Forest Model"
author: "Varun Vipul Chodanker"
format: html
editor: visual
---

## Random Forest Model

This document includes a random forest implementation on the re-balanced training data. Then, it tests its performance on the original test data.

## Setup

First, clear the environment, set configuration parameters and load the required libraries.

```{r}

# Reset environment
rm(list=ls())

# Config
options(java.parameters = "-Xmx4000m")

library(caret)
library(xlsx)
library(ranger)
library(dplyr)
```

## Data Loading and Preparation

Load the re-balanced training and original test datasets. Then, prepare them accordingly.

First define utility functions for data description, column name standardisation and target type preparation.

```{r}

# Utility functions

desc_bkrpt_data = function(data, name) {
  print("--- Bankruptcy Dataset")
  print(sprintf("Name: %s", name))
  print("Dimensions: ")
  dim(data)
  print(paste0(
    "Proportion that is bankrupt: ", 
    sum(data$y == 1)/dim(data)[1]
  ))
  print("Outline: ")
  str(data)
  print("---")
}

# Standardises column names assuming the target is first, then the features
standardise_column_names = function(data) {
  # Target
  names(data)[1] = "y"
  # Features
  names(data)[-1] = paste0('x', 1:(ncol(data)-1))
  
  return(data)
}

# Converts y target to categorical for the training of a classification model
prep_class_targ = function(data) {
  data$y = as.factor(data$y)
  return(data)
}
```

Load in the rebalanced training dataset and original test dataset.

```{r}

# Load the rebalanced training data in
rebalanced.train.data = read.xlsx("G2TR.xlsx", 1)
# Load the test data in
test.data = read.xlsx("test.xlsx", 1)
```

Load in the new adasyn optimised training dataset.

```{r}

adasyn.train.data = read.xlsx("adasyn_set.xlsx", 1)
```

Convert the target of the rebalanced training dataset.

```{r}
# Prepare the rebalanced training dataset

# Ensure target is categorical so that it is compatible with classification
rebalanced.train.data = prep_class_targ(rebalanced.train.data)

# Brief outline of the dataset
desc_bkrpt_data(rebalanced.train.data, "Rebalanced Train")
```

Rename the columns and convert the target of the test dataset.

```{r}
# Prepare the test dataset

# Standardise columns to y, x1, x2, ...
test.data = standardise_column_names(test.data)
# Convert the target to categorical so that it is compatible with classification applications
test.data = prep_class_targ(test.data)

# Brief outline of the result
desc_bkrpt_data(test.data, "Test")
```

Convert the target of the new adasyn training dataset.

```{r}

# Target conversion for classification
adasyn.train.data = prep_class_targ(adasyn.train.data)

# Describe the result
desc_bkrpt_data(adasyn.train.data, "Adasyn Training Data")
```

## Model Training and Evaluation

Train a random forest model on caret. Employ 5 fold cross validation that optimises accuracy. On both the rebalanced and new adasyn training sets.

```{r}

cv5fold <- trainControl(method="cv", number=5) # Create 5 fold cv control
# Train with the 5 fold CV on a random forest model, optimising accuracy
rebalanced.fit.rf <- train(
  y~., data=rebalanced.train.data, method="rf", metric="Accuracy", 
  trControl=cv5fold
)

adasyn.fit.rf <- train(
  y~., data=adasyn.train.data, method="rf", metric="Accuracy", 
  trControl=cv5fold
)
```

Report training performance of the two random forest models above.

```{r}
# Performance from the training
print(rebalanced.fit.rf)

print(adasyn.fit.rf)
```

Report the test performance of the two random forest models above.

```{r}
# Performance on reserved test data

# Expects standardised column names.
evaluate_model = function(model, eval_data) {
  # Make predictons
  eval_pred = NULL
  
  # Ensure just the raw predictions are extracted for further processing
  if (inherits(model, "ranger")) {
    eval_pred = predict(model, data=eval_data)
    eval_pred = eval_pred$predictions
  }
  else {
    eval_pred = predict(model, newdata=eval_data)  
  }
  # write.csv(eval_pred, "predictionsModel.csv")
  
  # Report performance with metrics and the confusion matrix
  postResample(pred=eval_pred, obs=eval_data$y)
  confusionMatrix(eval_pred, eval_data$y)  
}

evaluate_model(rebalanced.fit.rf, test.data)
evaluate_model(adasyn.fit.rf, test.data)

```

Train and evaluate a ranger model as the alternative

```{r}

#Compute weights to balance the RF
# w <- 1/table(train.data$y)
# w <- w/sum(w)
# weights <- rep(0, nrow(train.data))
# weights[train.data$y == 0] <- w['0']
# weights[train.data$y == 1] <- w['1']
# table(weights, train.data$y)

#Fit the RF
# train.df <- data.frame(train.data$Bankrupt., train.data[,2:ncol(train.data)])
# case.weights=weights
rebalanced.fit.rrf <- ranger(y~., rebalanced.train.data)
print(rebalanced.fit.rrf)
evaluate_model(rebalanced.fit.rrf, test.data)
# test.pred = predict(rebalanced.fit.rrf, data=test.data)
# postResample(pred=test.pred$predictions, obs=test.data$y)
# confusionMatrix(test.pred$predictions, test.data$y)
```

```{r}

adasyn.fit.rrf <- ranger(y~., adasyn.train.data)
print(adasyn.fit.rrf)
evaluate_model(adasyn.fit.rrf, test.data)
# test.pred = predict(adasyn.fit.rrf, data=test.data)
# postResample(pred=test.pred$predictions, obs=test.data$y)
# confusionMatrix(test.pred$predictions, test.data$y)
```

Attempt to increase weighting towards the +1 cases in training, on top of the balancing.

```{r}

# Expects standardised column names: y, x1, x2, ...
filter_features = function(data) {
  return(
    data %>%
      select(y,x39,x45,x49,x50,x52,x56,x59,x63,x64,x65,x70,x74,x75,x80,x83,x84,x85,x89)
  )
}

dr.adasyn.train.data <- filter_features(adasyn.train.data)

str(dr.adasyn.train.data)
```

```{r}

get_case_weights = function(data) {
  weights <- rep(0, nrow(data))
  weights[data$y == 0] = 0.03
  weights[data$y == 1] = 0.97
  print("Weight Assignment:")
  table(weights, data$y)
  
  return(
    weights
  )
}

get_class_weights = function() {
  return(c(0, 5000000))
}
```

```{r}

adasyn.fit.wrrf <- ranger(
  y~., adasyn.train.data, 
  case.weights=get_case_weights(adasyn.train.data), class.weights = get_class_weights()
)
print(adasyn.fit.wrrf)
evaluate_model(adasyn.fit.wrrf, test.data)
```

```{r}

adasyn.fit.csrf = csrf(y~., adasyn.train.data, test.data)
print(adasyn.fit.csrf)
```

```{r}

# worse performance (case-weighted random forests)
confusionMatrix(adasyn.fit.csrf, test.data$y)
```
